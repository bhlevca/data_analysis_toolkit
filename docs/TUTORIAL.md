# ğŸ“š Step-by-Step Tutorial: Advanced Data Analysis Toolkit v9

## Table of Contents

1. [Introduction](#introduction)
2. [Getting Started](#getting-started)
3. [Loading Your Data](#loading-your-data)
4. [Exploratory Data Analysis](#exploratory-data-analysis)
5. [Statistical Analysis](#statistical-analysis)
6. [Machine Learning](#machine-learning)
7. [Uncertainty Quantification](#uncertainty-quantification)
8. [Non-Linear Analysis](#non-linear-analysis)
9. [Time Series Analysis](#time-series-analysis)
10. [Causality Analysis](#causality-analysis)
11. [Decision Flowcharts](#decision-flowcharts)
12. [Common Workflows](#common-workflows)

---

## Introduction

The Advanced Data Analysis Toolkit is a comprehensive application for exploring, analyzing, and modeling your data. This tutorial will guide you through each feature step-by-step.

### What Can This Toolkit Do?

| Task | Capability |
|------|------------|
| ğŸ“Š Explore Data | Summary statistics, distributions, correlations |
| ğŸ¯ Detect Issues | Outliers, missing values, multicollinearity |
| ğŸ¤– Build Models | Linear regression, Random Forest, Gradient Boosting |
| ğŸ“ˆ Quantify Uncertainty | Bootstrap CI, Bayesian inference, Monte Carlo |
| ğŸ”€ Find Non-linear Patterns | Distance correlation, mutual information, GP |
| â±ï¸ Analyze Time Series | ACF/PACF, stationarity, ARIMA |
| ğŸ”— Test Causality | Granger causality, lead-lag analysis |

---

## Getting Started

### Launching the App

```bash
# Navigate to the toolkit directory
cd advanced_data_toolkit

# Install dependencies
pip install -e .
pip install streamlit

# Launch the Streamlit app
python run_streamlit.py

# Or directly:
streamlit run src/data_toolkit/streamlit_app.py
```

### Interface Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š Advanced Data Analysis Toolkit              [Sidebar: Tutorial]
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“ Data | ğŸ“Š Statistical | ğŸ¤– ML | ğŸ“ˆ Bayesian | ğŸ² Uncertainty â”‚
â”‚          | ğŸ”€ Non-Linear | â±ï¸ Time Series | ğŸ”— Causality | ğŸ“‰ Viz â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                        [Main Content Area]                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Sidebar Features:**
- ğŸ“š Tutorial Guide (toggle on/off)
- Select tutorial topic
- âš¡ Rust acceleration toggle

---

## Loading Your Data

### Step 1: Upload Your File

1. Click the **ğŸ“ Data Loading** tab
2. Click **"Browse files"** 
3. Select your CSV or Excel file
4. Wait for the upload confirmation âœ…

**Supported formats:** CSV, XLSX, XLS

### Step 2: Review Data Info

After loading, you'll see:
- **Rows**: Number of observations
- **Columns**: Number of variables
- **Memory**: Dataset size
- **Missing**: Count of missing values

### Step 3: Select Columns

| Selection | Purpose |
|-----------|---------|
| **Feature Columns** | Variables to analyze or use as predictors |
| **Target Column** | Variable to predict or explain |

**Tips:**
- Select multiple features using the multiselect dropdown
- Target is optional for exploratory analysis
- Start with a few columns, add more later

### Step 4: Preview Your Data

The data preview shows the first 10 rows. Use this to verify:
- âœ… Data loaded correctly
- âœ… Column names are sensible
- âœ… No obvious formatting issues

---

## Exploratory Data Analysis

**Goal:** Understand your data before modeling

### Recommended First Steps

```
1. Descriptive Statistics â†’ See distributions
2. Correlation Matrix    â†’ Find relationships
3. Box Plots            â†’ Spot outliers
4. Outlier Detection    â†’ Identify anomalies
```

### Understanding Descriptive Statistics

| Statistic | What It Tells You |
|-----------|-------------------|
| **Mean** | Average value |
| **Std** | Spread of values |
| **Min/Max** | Range of values |
| **25%/50%/75%** | Distribution shape |
| **Skewness** | Asymmetry (0 = symmetric) |
| **Kurtosis** | Tail heaviness (3 = normal) |

### Interpreting Correlations

```
Strong Positive:   r > 0.7    â†’ Variables increase together
Moderate Positive: 0.3 < r < 0.7
Weak:             -0.3 < r < 0.3 â†’ Little linear relationship
Moderate Negative: -0.7 < r < -0.3
Strong Negative:   r < -0.7   â†’ One increases, other decreases
```

### When to Worry About Outliers

Consider removing outliers if:
- They're data entry errors
- They're from a different population
- They significantly affect your model

Keep outliers if:
- They're genuine extreme observations
- They contain important information
- Your analysis method is robust to outliers

---

## Statistical Analysis

### Analysis Selection Guide

**"I want to understand my data"**
â†’ Use: Descriptive Statistics

**"I want to see relationships"**
â†’ Use: Correlation Matrix
- Pearson: For linear relationships
- Spearman: For monotonic relationships (ranked data)
- Kendall: For ordinal data

**"I want to find unusual values"**
â†’ Use: Outlier Detection
- IQR method: Robust, no distribution assumptions
- Z-score: Assumes normal distribution

### Step-by-Step: Correlation Analysis

1. Go to **ğŸ“Š Statistical** tab
2. Select correlation method (start with Pearson)
3. Click **ğŸ”— Correlation Matrix**
4. Interpret the heatmap:
   - ğŸ”µ Blue = positive correlation
   - âšª White = no correlation
   - ğŸ”´ Red = negative correlation

### Step-by-Step: Outlier Detection

1. Go to **ğŸ“Š Statistical** tab
2. Select method: IQR (recommended) or Z-score
3. Click **ğŸ¯ Outlier Detection**
4. Review results for each column:
   - Count of outliers
   - Percentage of data affected
   - Bounds used for detection

---

## Machine Learning

### Choosing the Right Model

```
Start Here
    â”‚
    â–¼
Is relationship linear? â”€â”€Yesâ”€â”€â–º Linear Regression
    â”‚
    No
    â–¼
Do you have many features? â”€â”€Yesâ”€â”€â–º Lasso (auto feature selection)
    â”‚                               or Ridge (handles collinearity)
    No
    â–¼
Do you need interpretability? â”€â”€Yesâ”€â”€â–º Decision Tree
    â”‚
    No
    â–¼
Do you need best accuracy? â”€â”€Yesâ”€â”€â–º Gradient Boosting
    â”‚
    No
    â–¼
Random Forest (good default for non-linear)
```

### Step-by-Step: Training a Model

1. Go to **ğŸ¤– ML** tab
2. Select model type from dropdown
3. Adjust parameters if needed:
   - **Alpha** for Ridge/Lasso (higher = more regularization)
   - **n_estimators** for tree models (more = better but slower)
4. Click **ğŸ¯ Train Model**
5. Review metrics:
   - **RÂ²**: Higher is better (1.0 = perfect)
   - **RMSE**: Lower is better (in original units)
   - **MAE**: Lower is better (typical error)

### Step-by-Step: Cross-Validation

**Why do this?** To get reliable performance estimates

1. Set number of folds (5 is standard)
2. Click **ğŸ”„ Cross-Validation**
3. Look at:
   - Mean score: Expected performance
   - Std: Stability (lower = more stable)

### Understanding Feature Importance

1. Train a model first (Random Forest works best)
2. Click **ğŸ“Š Feature Importance**
3. Interpret the bar chart:
   - Longer bars = more important features
   - Consider removing low-importance features

---

## Uncertainty Quantification

### When to Use Each Method

| Method | Use When |
|--------|----------|
| Bootstrap CI | You want robust confidence intervals |
| Monte Carlo | You need prediction uncertainty |
| Residual Analysis | You want to validate model assumptions |

### Step-by-Step: Bootstrap Confidence Intervals

1. Go to **ğŸ² Uncertainty** tab
2. Set parameters:
   - **Bootstrap samples**: 1000 is good (more = more precise)
   - **Confidence level**: 0.95 is standard
3. Click **ğŸ”„ Bootstrap CI**
4. Interpret results:
   - **Mean**: Best estimate of coefficient
   - **Std Error**: Uncertainty in estimate
   - **CI bounds**: True value likely within this range

### Step-by-Step: Residual Analysis

**Always do this after fitting a model!**

1. Click **ğŸ¯ Residual Analysis**
2. Check the diagnostics:

| Diagnostic | Good Value | Problem If |
|------------|------------|------------|
| Durbin-Watson | â‰ˆ 2.0 | < 1.5 or > 2.5 (autocorrelation) |
| Normality p-value | > 0.05 | < 0.05 (non-normal residuals) |
| Q-Q Plot | Points on line | Points curve away |

3. If problems exist:
   - Transform variables
   - Add missing predictors
   - Try different model

---

## Non-Linear Analysis

### Key Concept: Pearson vs Distance Correlation

```
Pearson correlation only detects LINEAR relationships!

Example:
  y = xÂ²  â†’  Pearson r â‰ˆ 0  (misses the relationship!)
            Distance corr â‰ˆ 0.7 (detects it!)
```

### Step-by-Step: Detecting Non-Linear Relationships

1. Go to **ğŸ”€ Non-Linear** tab
2. Click **ğŸ“Š Distance Correlation**
3. Compare with Pearson:
   - Similar values â†’ Linear relationship
   - Distance >> Pearson â†’ Non-linear relationship!

### When Distance Correlation Helps

| Relationship | Pearson | Distance | Conclusion |
|--------------|---------|----------|------------|
| y = 2x + 1 | 0.99 | 0.99 | Linear âœ… |
| y = xÂ² | 0.02 | 0.68 | Non-linear! Use polynomial |
| y = sin(x) | 0.05 | 0.71 | Non-linear! |
| Independent | 0.01 | 0.03 | No relationship |

### Step-by-Step: Polynomial Regression

1. First, plot your data to guess the degree needed
2. Select feature and polynomial degree
3. Click **ğŸ“ˆ Polynomial Regression**
4. Start with degree 2, increase if RÂ² is low
5. **Warning**: degree > 4 often overfits!

---

## Time Series Analysis

### The Time Series Workflow

```
Step 1: Plot the series
    â”‚
    â–¼
Step 2: Check stationarity (ADF test)
    â”‚
    â”œâ”€â”€ Stationary (p < 0.05) â”€â”€â–º Continue to Step 3
    â”‚
    â””â”€â”€ Non-stationary â”€â”€â–º Difference the data, repeat Step 2
    â”‚
    â–¼
Step 3: Examine ACF/PACF
    â”‚
    â–¼
Step 4: Identify model (AR, MA, ARMA)
    â”‚
    â–¼
Step 5: Fit and validate
```

### Step-by-Step: Stationarity Test

1. Go to **â±ï¸ Time Series** tab
2. Select your time series column
3. Click **ğŸ”¬ Stationarity Test**
4. Interpret:
   - **p < 0.05**: Series IS stationary âœ…
   - **p â‰¥ 0.05**: Series is NOT stationary âš ï¸

### Step-by-Step: Reading ACF/PACF

**ACF (Autocorrelation Function)**
- Shows correlation with lagged values
- Use to identify MA order

**PACF (Partial ACF)**
- Shows direct correlation (controlling for intermediate lags)
- Use to identify AR order

| Pattern | ACF | PACF | Model |
|---------|-----|------|-------|
| AR(p) | Tails off | Cuts off at lag p | AR(p) |
| MA(q) | Cuts off at lag q | Tails off | MA(q) |
| ARMA | Tails off | Tails off | ARMA |

### Step-by-Step: Decomposition

1. Click **ğŸ”„ Decomposition**
2. View the four components:
   - **Observed**: Original series
   - **Trend**: Long-term direction
   - **Seasonal**: Repeating pattern
   - **Residual**: What's left (should be noise)

---

## Causality Analysis

### âš ï¸ Important Warning

**Granger causality â‰  True causation!**

Granger causality tests if X helps *predict* Y, not if X *causes* Y.

### Step-by-Step: Granger Causality Test

1. Go to **ğŸ”— Causality** tab
2. Select the feature to test
3. Set max lag (start with 10)
4. Click **ğŸ”¬ Granger Causality**
5. Interpret:
   - **p < 0.05**: X Granger-causes Y (has predictive power)
   - **p â‰¥ 0.05**: X does NOT Granger-cause Y

### Step-by-Step: Lead-Lag Analysis

1. Click **â±ï¸ Lead-Lag Analysis**
2. Find the best lag:
   - **Lag < 0**: X leads Y (X predicts future Y)
   - **Lag = 0**: Contemporaneous (move together)
   - **Lag > 0**: Y leads X (Y predicts future X)

### Example Interpretation

```
Best Lag: -3
Max Correlation: 0.75

Interpretation:
"Feature X leads Target Y by 3 periods with correlation 0.75"
"X might be a leading indicator for Y"
```

---

## Decision Flowcharts

### What Analysis Should I Use?

```
What's your goal?
    â”‚
    â”œâ”€â”€ Understand my data
    â”‚       â””â”€â”€ ğŸ“Š Statistical â†’ Descriptive Stats, Correlations
    â”‚
    â”œâ”€â”€ Predict a value
    â”‚       â””â”€â”€ ğŸ¤– ML â†’ Train model, Cross-validate
    â”‚
    â”œâ”€â”€ Understand uncertainty
    â”‚       â””â”€â”€ ğŸ² Uncertainty â†’ Bootstrap CI, Monte Carlo
    â”‚
    â”œâ”€â”€ Check for non-linear patterns
    â”‚       â””â”€â”€ ğŸ”€ Non-Linear â†’ Distance Correlation, GP
    â”‚
    â”œâ”€â”€ Analyze time-dependent data
    â”‚       â””â”€â”€ â±ï¸ Time Series â†’ ACF/PACF, ARIMA
    â”‚
    â””â”€â”€ Test if X predicts/causes Y
            â””â”€â”€ ğŸ”— Causality â†’ Granger Test, Lead-Lag
```

### Which Correlation Method?

```
What type of data?
    â”‚
    â”œâ”€â”€ Continuous, normally distributed
    â”‚       â””â”€â”€ Pearson
    â”‚
    â”œâ”€â”€ Continuous, non-normal OR monotonic relationship
    â”‚       â””â”€â”€ Spearman
    â”‚
    â”œâ”€â”€ Ordinal (ranked categories)
    â”‚       â””â”€â”€ Kendall
    â”‚
    â””â”€â”€ Potentially non-linear
            â””â”€â”€ Distance Correlation
```

### Which ML Model?

```
What do you need?
    â”‚
    â”œâ”€â”€ Interpretable coefficients
    â”‚       â””â”€â”€ Linear Regression
    â”‚
    â”œâ”€â”€ Handle multicollinearity
    â”‚       â””â”€â”€ Ridge Regression
    â”‚
    â”œâ”€â”€ Automatic feature selection
    â”‚       â””â”€â”€ Lasso Regression
    â”‚
    â”œâ”€â”€ Non-linear relationships
    â”‚       â””â”€â”€ Random Forest or Gradient Boosting
    â”‚
    â””â”€â”€ Best predictive accuracy
            â””â”€â”€ Gradient Boosting (usually)
```

---

## Common Workflows

### Workflow 1: Quick Data Exploration

```
1. Load data                          [ğŸ“ Data Loading]
2. Check descriptive stats            [ğŸ“Š Statistical]
3. Look at correlation heatmap        [ğŸ“Š Statistical]
4. Create box plots for outliers      [ğŸ“‰ Visualization]
5. Check scatter matrix               [ğŸ“‰ Visualization]
```

### Workflow 2: Building a Predictive Model

```
1. Load data                          [ğŸ“ Data Loading]
2. Check for outliers                 [ğŸ“Š Statistical]
3. Check correlations                 [ğŸ“Š Statistical]
4. Check for non-linearity            [ğŸ”€ Non-Linear]
5. Train Linear Regression (baseline) [ğŸ¤– ML]
6. Try Random Forest                  [ğŸ¤– ML]
7. Cross-validate best model          [ğŸ¤– ML]
8. Check residuals                    [ğŸ² Uncertainty]
9. Get confidence intervals           [ğŸ² Uncertainty]
```

### Workflow 3: Time Series Forecasting

```
1. Load time series data              [ğŸ“ Data Loading]
2. Plot and visualize                 [ğŸ“‰ Visualization]
3. Test stationarity                  [â±ï¸ Time Series]
4. If non-stationary, difference      [External]
5. Examine ACF/PACF                   [â±ï¸ Time Series]
6. Decompose to see components        [â±ï¸ Time Series]
7. Fit ARIMA model                    [â±ï¸ Time Series]
```

### Workflow 4: Investigating Causal Relationships

```
1. Load data                          [ğŸ“ Data Loading]
2. Check correlations                 [ğŸ“Š Statistical]
3. Check for non-linear relationships [ğŸ”€ Non-Linear]
4. Run lead-lag analysis              [ğŸ”— Causality]
5. Test Granger causality             [ğŸ”— Causality]
6. Interpret with caution!            [Remember: correlation â‰  causation]
```

---

## Tips for Best Results

### Data Preparation
- âœ… Remove or handle missing values
- âœ… Check for and address outliers
- âœ… Scale features for neural networks/SVM
- âœ… Log-transform heavily skewed variables

### Model Selection
- âœ… Start simple (Linear Regression)
- âœ… Use cross-validation for fair comparison
- âœ… Check residuals after fitting
- âœ… Consider interpretability vs accuracy trade-off

### Interpretation
- âœ… Report confidence intervals, not just point estimates
- âœ… Check statistical significance
- âœ… Be cautious about causal claims
- âœ… Validate on held-out data

### Performance
- âœ… Enable Rust acceleration for large datasets
- âœ… Start with fewer bootstrap samples, increase if needed
- âœ… Limit features in scatter matrix to 5

---

*Tutorial Version 9.0 - Last Updated December 2024*
